<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Control Theory note</title>
    <url>/2021/09/13/Control_Theory_note/</url>
    <content><![CDATA[<h1 id="Lecture-1"><a href="#Lecture-1" class="headerlink" title="Lecture 1"></a>Lecture 1</h1><p>控制: 使受控对象产生预期相应 (按照预期方式工作).</p>
<p>输入(激励) —&gt; 输出(相应)</p>
<p>自动控制: 无人参与情况下, 利用控制装置使受控对象的某一受控变量自动按照预定规律运行.</p>
<p>受控对象: 要求实现自动工作的机器, 设备或生产过程. 有多个受控变量.</p>
<ul>
<li><p>开环控制: 利用执行机构直接控制受控对象, 信息单向流动</p>
<ul>
<li>控制量 $u(t)$ —&gt; 执行机构(油门, 方向盘) —&gt; 受控对象 —&gt; 输出 $y(t)$​</li>
</ul>
</li>
<li><p>闭环控制: 有反馈过程, 信息双向流动</p>
<ul>
<li><p>预期输入 $r(t)$ —&gt; 比较器 —&gt; 误差$e(t)$ —&gt; 控制器 —&gt; 控制量$u(t)$ —&gt; 受控对象 —&gt; 实际输出 $y(t)$</p>
<p>​                                    $\uparrow$​​ &lt;———- 测量值 &lt;———- 测量装置 &lt;———- 被测变量 &lt;———- $\downarrow$​​</p>
</li>
</ul>
<h2 id="HW-1"><a href="#HW-1" class="headerlink" title="HW 1"></a>HW 1</h2></li>
</ul>
<h3 id="1-1"><a href="#1-1" class="headerlink" title="1-1"></a>1-1</h3><ul>
<li>输出变量: 激光器的实际输出功率</li>
<li>输入变量: 激光器预期输出的功率</li>
<li>待测变量: 传感器测量得到的, 与激光器的实际输出功率成比例的信号</li>
<li>控制装置: 微处理器</li>
</ul>
<h3 id="1-2"><a href="#1-2" class="headerlink" title="1-2"></a>1-2</h3><p>…</p>
<h1 id="Lecture-2"><a href="#Lecture-2" class="headerlink" title="Lecture 2"></a>Lecture 2</h1><ul>
<li>经典控制理论: 传递函数</li>
<li>现代控制理论: 状态空间方程</li>
</ul>
<p>都要微分方程</p>
<ul>
<li>时间域: 微分/差分方程, 状态方程</li>
<li>复数域: 传递函数, 结构图</li>
<li>频率域: 频率特性函数</li>
</ul>
<p>微分方程模型:</p>
<ul>
<li>确定输入量, 输出量</li>
<li>根据设定写方程</li>
<li>消除中间量, 保留输入, 输出</li>
<li>标准化: 等式右边/左边与输入/输出变量有关</li>
</ul>
<p>线性定常(时不变): 系数不变</p>
<p>线性系统:</p>
<ul>
<li>叠加性: $ y(x_1+x_2) = y(x_1) + y(x_2)$</li>
<li>齐次性: $y(\beta x ) = \beta y(x)$</li>
</ul>
<p>一般$n$​阶线性定常微分方程模型: $y(t)$ 为输出, $r(t)$ 为输入, $m&lt;n$, $a,b$ 均为实数, 为系统参数</p>
<p>$a_0 \frac{d^n}{dt^n}y(t) + a_1 \frac{d^{n-1}}{dt^{n-1}}y(t) + \cdots + a_{n-1} \frac{d^{}}{dt^{}}y(t) + a_n y_t = b_0 \frac{d^m}{dt^m}r(t) + b_1 \frac{d^{m-1}}{dt^{m-1}}r(t) + \cdots + b_{m-1} \frac{d^{}}{dt^{}}r(t) + b_m r_t $​</p>
<p>建立线性化近似模型策略:</p>
<ol>
<li>限制范围, 使系统工作在线性区, 忽略非线性. $y = \frac{dy}{dx}|_{x_0} x$​</li>
<li>小信号 : 泰勒展开</li>
</ol>
<hr>
<p>时间域 $f(t)$ —&gt; 傅立叶变换  —&gt; 频率域 $F(\omega)$​ —&gt; 傅立叶反变换 —&gt; $f(t)$​</p>
<p>傅立叶变换: $F(\omega) = \int _{-\infty} ^ {+\infty} e^{-j\omega t} f(t)dt$</p>
<p>拉普拉斯变换: $L(s) = \int _{0} ^ {+\infty} e^{-(\sigma + j \omega ) t} f(t)dt$​, 复数 $s = \sigma + j \omega$​</p>
<p>$F(s) = L(f(t)) = \int _0 ^\infty f(t)e^{-st}dt$ </p>
<p>拉氏变换可理解为广义单边傅立叶变换, 是线性变换</p>
<p>$F(s)$​ 为 $f(t)$ 的拉氏变换或象函数, $f(t)$ 为 $F(s)$​ 的原函数, 一一对应. </p>
<ul>
<li>指数函数: $f(t) = Ae^{-at} \rightarrow L(f(t)) = \frac{A}{s+a}$, 极点 $s = -a$</li>
<li>单位阶跃函数: $0,1 \rightarrow \frac{1}{s}$, 极点 $s = 0$</li>
<li>斜坡函数: $ At \rightarrow \frac{A}{s^2}$, 极点 $s_{1,2} = 0$</li>
<li>幂函数: $ t^n \rightarrow   \frac{n!}{s^{n+1}}$​</li>
<li>正弦函数: $\sin \omega t  \rightarrow \frac{\omega}{s^2 + \omega^2}$ , 极点 $s_{1,2} = \pm j \omega$</li>
<li>余弦函数: $ \cos \omega t \rightarrow \frac{s}{s^2 + \omega^2}$​ , 极点 $s_{1,2} = \pm j \omega$</li>
<li>单位脉冲函数: $\lim\limits_{\epsilon \rightarrow 0} \frac{1}{\epsilon} \rightarrow 1$</li>
</ul>
<p>五大定理</p>
<ul>
<li>位移定理<ul>
<li>时间 $t$​​ 平移 $L[f(t-a)] = e^{-as}F(s)$</li>
<li>频率域 $s$​​​ 平移 $L[f(t)e^{-at}] = F(s+a)$</li>
<li>时间 $t$​​ 尺度变换 $L[f(\frac{t}{a})] = aF(as)$</li>
</ul>
</li>
<li><strong>微分定理</strong><ul>
<li>$L[\frac{d}{dt} f(t)] = sF(s) - f(0)$​</li>
<li>$L[\frac{d^2}{dt^2} f(t)] = s^2F(s) - sf(0)- f’(0)$</li>
<li>$L[\frac{d^n}{dt^n} f(t)] = s^nF(s) - s^{n-1}f(0) - \cdots -sf^{(n-2)}(0) - f^{(n-1)}(0)$​</li>
<li>零初始条件 $L[\frac{d^n}{dt^n} f(t)] = s^nF(s)$</li>
</ul>
</li>
<li>积分定理<ul>
<li>$L(\int f(t)dt) = \frac{F(s)}{s} + \frac{f^{-1}(0)}{s},~f^{-1}(0) = \int_{-\infty}^0 f(t)dt$</li>
<li>$L(\int \int f(t)dt) = \frac{F(s)}{s^2} + \frac{f^{-1}(0)}{s^2} + \frac{f^{-2}(0)}{s},~f^{-1}(0) = \int_{-\infty}^0 f(t)dt$</li>
<li>零初始条件 $L[\int\int\cdots\int f(t)dt^n] = \frac{F(s)}{s^n}$</li>
</ul>
</li>
<li><strong>终值定理</strong><ul>
<li>$\lim\limits_{t\rightarrow\infty} = \lim_\limits{s\rightarrow0}sF(s)$</li>
</ul>
</li>
<li>初值定理<ul>
<li>$\lim\limits_{t \rightarrow 0} f(t) = \lim\limits_{s \rightarrow \infty} sF(s) $​</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21091701.png" alt=""></p>
<h1 id="Lecture-3"><a href="#Lecture-3" class="headerlink" title="Lecture 3"></a>Lecture 3</h1><p>拉氏反变换 $f(t) = L^{-1} [F(s)]$</p>
<p>可将 $F(s)$​ 分解为典型函数的叠加 $L^{-1}[F(s)] = L^{-1}[F_1(s)] + L^{-1}[F_2(s)] + … +L^{-1}[F_n(s)]$​</p>
<p> 通常 $F(s) = \frac{B(s)}{A(s)} =\frac{b_{0}s^{m} + b_{1}s^{m-1} + … + b_{m-1}s^{} + b_{m}}{a_{0}s^{n} + a_{1}s^{n-1} + … + a_{n-1}s^{} + a_{n}} = \frac{c_{0}s^{m} + c_{1}s^{m-1} + … + c_{m-1}s^{} + c_{m}}{(s+p_1)(s+p_2)…(s+p_n)} $</p>
<p>$F(s)$ 的极点: 使分母 $A(s) = 0$ 的根​</p>
<p>$F(s)$ 的零点: 使分子 $B(s) = 0$ 的根​</p>
<ol>
<li>$F(s)$ 只有不同的实数极点 $F(s) = \sum\limits _{i=1} ^n \frac{A_i}{s+p_i} \Rightarrow L^{-1}[F(s)] = \sum\limits _{i=1} ^n L^{-1} [\frac{A_i}{s+p_i}] = \sum\limits _{i=1} ^n A_i e^{-p_i t}$ </li>
<li>$F(s)$​​ 有共轭复数极点 $\frac{s+1}{s(s^2+s+1)} = \frac{A}{s} + \frac{Bs+C}{s^2+s+1}$</li>
<li>$F(s)$ 有重极点 $\frac{s+3}{(s+2)^2(s+1)} = \frac{A}{(s+2)^2}+\frac{B}{(s+2)} + \frac{C}{s+1}$</li>
</ol>
<p>用拉氏变换求微分方程</p>
<ol>
<li>将方程通过拉氏变换变为 $s$ 的代数方程</li>
<li>解代数方程得到 $F(s)$</li>
<li>反变换回时域解 $f(t)$</li>
</ol>
<p>受控变量运动模态取决于其变换函数 $Y(s)$​ 的极点(分母多项式方程的根)</p>
<ul>
<li>$s = -a \Leftrightarrow e^{-at}$</li>
<li>$s = \pm j \omega \Leftrightarrow \sin(\omega t)$</li>
</ul>
<p>传递函数: 在0初始条件下, 系统输出量的拉氏变换与输入量拉氏变换的比值</p>
<p>只适用于线性定常系统</p>
<p>$G(s) = \frac{b_{0}s^{m} + b_{1}s^{m-1} + … + b_{m-1}s^{} + b_{m}}{a_{0}s^{n} + a_{1}s^{n-1} + … + a_{n-1}s^{} + a_{n}} = \frac{M(s)}{N(s)}$​</p>
<p>$n \ge m$, 系数均为实数</p>
<p>放大系数(增益): $G(0) = \frac{b_m}{a_n} = K$</p>
<p>$N(s) = 0$ 称为系统的特征方程, 其根为系统的特征根, $s$ 的最高阶次等于系统的阶次</p>
<h2 id="HW3"><a href="#HW3" class="headerlink" title="HW3"></a>HW3</h2><h3 id="2-6"><a href="#2-6" class="headerlink" title="2-6"></a>2-6</h3><p>(a) $r(t)$ 为单位阶跃函数, $R(s) = L(r(t)) = \frac{1}{s}, Y(s) = \frac{4(s+50)}{s(s^2 + 30s + 200)} = \frac{1}{s} - \frac{8}{5} \frac{1}{s+10} + \frac{3}{5}\frac{1}{s+20}$</p>
<p>​     $y(t) = L^{-1}(Y(s)) = 1 - \frac{8}{5} e^{-10t} + \frac{3}{5} e^{-20t}$</p>
<p>(b) 由题意 $\lim_{t\rightarrow \infty} y(t)$​ 存在, $y(t)$​ 存在拉氏变换</p>
<h1 id="Lecture-X"><a href="#Lecture-X" class="headerlink" title="Lecture X"></a>Lecture X</h1><p>二阶系统的时域响应性能分析</p>
<p>$G(s)=\frac{\omega_n^2}{s(s+2\zeta\omega_n)},~H(s)=1$</p>
<p>$\Phi(s) = \frac{G}{1+GH} = \frac{\omega_n^2}{s^2 + 2\zeta \omega_ns+\omega_n^2}$</p>
<p>梦开始的地方, 可见二阶系统由2个参数决定: $\zeta,~\omega_n$</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">symbol</th>
<th style="text-align:center">CHN</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$\zeta$</td>
<td style="text-align:center">阻尼系数, 阻尼比</td>
</tr>
<tr>
<td style="text-align:center">$\omega_n$</td>
<td style="text-align:center">系统固有频率, 自然振荡频率</td>
</tr>
<tr>
<td style="text-align:center">$\sigma = \zeta\omega_n$</td>
<td style="text-align:center">衰减系数, 负的实部</td>
</tr>
<tr>
<td style="text-align:center">$\omega_d = \omega_n \sqrt{1-\zeta^2}$</td>
<td style="text-align:center">阻尼频率, 虚部</td>
</tr>
<tr>
<td style="text-align:center">$\frac{\zeta}{\sqrt{1-\zeta^2}}$</td>
<td style="text-align:center">根实部虚部之比</td>
</tr>
<tr>
<td style="text-align:center">$\beta=\arctan{\frac{\sqrt{1-\zeta^2}}{\zeta}}$</td>
<td style="text-align:center">阻尼角</td>
</tr>
<tr>
<td style="text-align:center">T=$\frac{1}{\zeta\omega_n}$</td>
<td style="text-align:center">广义时间常数</td>
</tr>
</tbody>
</table>
</div>
<p>$\zeta \in$</p>
<ul>
<li>(0,1):       <strong>欠阻尼系统, 重点</strong> </li>
<li>{1}:          临界阻尼系统</li>
<li>(1, $+\infty$​​): 过阻尼系统</li>
<li>{0}:          零阻尼系统</li>
<li>($-\infty$​, 0): 负阻尼系统</li>
</ul>
<p>以下讨论欠阻尼系统</p>
<p>$s^2 + 2\zeta \omega_ns+\omega_n^2 = 0$​​​, 极点 $s_{1,2}=-\zeta\omega_n \pm j\omega_n\sqrt{1-\zeta^2}=-\sigma\pm j\omega_d$​​</p>
<p>一对共轭复根​​​</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021101602.png" alt=""></p>
<p>单位阶跃响应 $Y(s) = \frac{1}{s}\cdot\Phi(s)$</p>
<p>$y(t) = 1 - e^{-\zeta\omega_nt} [\cos(\sqrt{1-\zeta^2} \omega_nt) + \frac{\zeta}{\sqrt{1-\zeta^2}}\sin(\sqrt{1-\zeta^2} \omega_nt)] = 1 - \frac{e^{-\zeta\omega_nt}}{\sqrt{1-\zeta^2}} \sin(\omega_dt+\beta)$​</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021101601.png" style="zoom: 67%;" /></p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021101603.png" style="zoom:67%;" /></p>
<ul>
<li><p>零稳态误差: $\lim_{t\rightarrow\infty}y(t)=1$</p>
</li>
<li><p>上升时间 $t_r$: 令 $\sin = 0$ 得 $t_r = \frac{\pi-\beta}{\omega_d}$ </p>
</li>
<li><p>峰值时间 $t_p$: 令 $\frac{dy(t)}{dt}=0$ 得 $\tan(\omega_dt+\beta) = \frac{\omega_d}{\zeta\omega_n} = \tan(\beta)~\Rightarrow ~\omega_dt_p=n\pi=\pi$ 得 $t_p = \frac{\pi}{\omega_d}$</p>
</li>
<li><p>超调量 P.O. $y(t_p) = 1+e^{-\frac{\zeta\pi}{\sqrt{1-\zeta^2}}},~y(\infty)=1,~P.O.=e^{-\frac{\zeta\pi}{\sqrt{1-\zeta^2}}} \cdot 100\%$, <strong>由$\zeta$唯一决定</strong></p>
<p>  |    $\zeta$  |  P.O.    |  实虚比例    |<br>  | :——: | :——: | :——: |<br>  | 0.707 | &lt;5% | 1:1 |<br>  | 0.6 | &lt;10% | 3:4 |<br>  | 0.45 | $\approx$20% | 1:2 |<br>  | 0.32 | &lt;35% | 1:3 |</p>
</li>
<li><p>调节时间 $t_s$: 令 $\frac{e^{-\zeta\omega_nt_s}}{\sqrt{1-\zeta^2}} =\delta$ 得 $t_s \approx \frac{-\ln\delta}{\zeta\omega_n}$</p>
<ul>
<li>5% 准则, $\delta=5\%,~t_s\approx3T$</li>
<li>2% 准则, $\delta=2\%,~t_s\approx4T$</li>
<li>若精确计算, 当 $\omega_n$ 一定, $\zeta=0.707~(\beta = \pi/2)$ 时 $t_s$ 最小. $\zeta$ 一定时, 固有频率 $\omega_n$ 越大则 $t_s$ 越小.</li>
</ul>
</li>
</ul>
<hr>
<p>极点 $s_{1,2}=-\zeta\omega_n \pm j\omega_n\sqrt{1-\zeta^2}=-\sigma\pm j\omega_d$</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021101604.png" style="zoom:50%;" /></p>
<ul>
<li>等阻尼线, $\beta$ 线, P.O.线</li>
</ul>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021101605.png" style="zoom:33%;" /></p>
<p>​       线上系统的 P.O. 都相同, $\beta$ 越大的线, 实虚比例越小, P.O.越大.</p>
<ul>
<li>等 $\omega_n$ 线: 以原点的中心, $\omega_n$ 为半径的圆, 圆上点 $\omega_n$ 都相等</li>
</ul>
<ul>
<li>等 $t_s$ 线: 竖直线, 越左, 实部越小, $\zeta\omega_n$ 越大, $t_s$ 越小</li>
<li>等 $t_p$ 线: 水平线, 离原点越远, 虚部越大, $t_p$ 越小</li>
</ul>
<h1 id="Lecture-X-1"><a href="#Lecture-X-1" class="headerlink" title="Lecture X+1"></a>Lecture X+1</h1><p>高阶系统</p>
<p>瞬态响应由一些一阶惯性环节和二阶振荡环节的响应函数叠加组成的.</p>
<p>当所有闭环极点均具有负实部时, 系统稳定.</p>
<hr>
<p>研究高阶 (二阶系统的有限扩展)</p>
<ul>
<li><p>额外闭环零点</p>
<p>$\Phi(s) = \frac{\omega_n^2}{s^2+2\zeta\omega_ns+\omega_n^2}\left(\frac{s+z}{z}\right)$</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021102201.png" style="zoom:67%;" /></p>
<p>增加了微分环节, 波动增强</p>
<p>$y’(t) = 1 - y(t) + \frac{\omega_n}{z}\frac{e^{-\zeta\omega_nt}}{\sqrt{1-\zeta^2}}\sin(\sqrt{1-\zeta^2}\omega_n t)$</p>
</li>
<li><p>额外闭环极点</p>
<p>$\Phi(s) = \frac{\omega_n^2}{s^2+2\zeta\omega_ns+\omega_n^2}\left(\frac{p}{s+p}\right)$</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021102202.png" style="zoom:67%;" /></p>
<p>增加了积分环节, 波动减弱. 其中 $p$ 对瞬态行为的影响可以忽略</p>
<blockquote>
<p>上述 $z,~p$ 的作用是 $s\rightarrow0 (t\rightarrow\infty)$ 时系统相应不变</p>
</blockquote>
</li>
</ul>
<hr>
<p>高阶的简化</p>
<ul>
<li><p>忽略非主导极点</p>
<p>主导极点: 靠近虚轴且附近没有零点的极点, 实部为 $\zeta\omega_n$</p>
<p>可以忽略实部为 $N\zeta\omega_n~(N\ge0)$ 的远端极点</p>
</li>
<li><p>偶极子相消</p>
<p>一极点与一零点之间的距离 &lt; 它们本身到原点距离的 1/10, 可以消掉 (太阳是原点, 消掉海王星及其卫星)</p>
</li>
</ul>
<p>只有负实部的点可以消, 且要保持系统静态增益不变</p>
<p>eg. $\frac{Y(s)}{R(s)} = \frac{s+20.03}{(s+20)(s+100)(…)}\approx\frac{1}{(s+100)(…)}\approx\frac{1}{100(…)}$</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021102203.png" style="zoom:67%;" /></p>
<hr>
<p>稳态性能分析</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021102204.png" style="zoom:67%;" /></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">$X_i(s)$</th>
<th style="text-align:center">系统输入</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$X_o(s)$</td>
<td style="text-align:center">实际系统输出</td>
</tr>
<tr>
<td style="text-align:center">$X_{oi}(s)$</td>
<td style="text-align:center">理想系统输出</td>
</tr>
<tr>
<td style="text-align:center">$N(s)$</td>
<td style="text-align:center">干扰</td>
</tr>
<tr>
<td style="text-align:center">$E(s) = X_{oi}(s) - X_{o}(s)$</td>
<td style="text-align:center">误差, 理想输出和实际输出之差</td>
</tr>
<tr>
<td style="text-align:center">$\epsilon(s) = X_{i}(s) - H(s)X_o(S)$</td>
<td style="text-align:center">偏差, 系统输入信号与反馈信号之差</td>
</tr>
<tr>
<td style="text-align:center">$e_{ss} = \lim_{t\rightarrow\infty} e(t)$</td>
<td style="text-align:center">稳态误差</td>
</tr>
<tr>
<td style="text-align:center">$\epsilon_{ss} = \lim_{t\rightarrow\infty} \epsilon(t)$</td>
<td style="text-align:center">稳态偏差</td>
</tr>
</tbody>
</table>
</div>
<p>$\frac{X_o(s)}{X_i(s)} = \frac{G}{1+GH}$</p>
<p>当 $GH&gt;&gt;1,~\frac{X_o(s)}{X_i(s)} \approx \frac{1}{H}$</p>
<p>$X_{oi}(s) = \frac{1}{H} X_i(s)$</p>
<p>$E(s) = X_{oi}(s) - X_{o}(s) =\frac{1}{H} X_i(s) - \frac{HX_o(S)}{H} = \frac{\epsilon(s)}{H}$</p>
<p>若已知 $H$, 可由稳态偏差求得稳态误差.</p>
<p>单位负反馈: 偏差 = 误差</p>
<p>系统误差由<strong>输入</strong>与<strong>干扰</strong>引起的误差造成.</p>
<p>可利用叠加原理直接相加二者求出系统误差.</p>
<hr>
<p>输入引起的稳态误差</p>
<p><strong>偏差传递函数 $\frac{\epsilon(s)}{X_i(s)} = \frac{1}{1+GH}$</strong></p>
<p>稳态误差 $e_{ss}=\frac{\epsilon_{ss}}{H(0)}$</p>
<p>$ = \frac{1}{H(0)}\lim_{s\rightarrow0}s\cdot\epsilon(s) = \frac{1}{H(0)}\lim_{s\rightarrow0}s\cdot \frac{X_i(s)}{1+GH}$ </p>
<p>取决于系统参数与输入信号</p>
<p>计算方法:</p>
<ul>
<li>根据系统型次快速得到</li>
<li>利用偏差传递函数+终值定理</li>
</ul>
<hr>
<p>干扰引起的稳态误差</p>
<p><strong>干扰传递函数</strong> $\frac{X_o(s)}{N(s)} = \frac{G_2}{1+G_1G_2H}$</p>
<p><strong>干扰偏差传递函数</strong> $\frac{\epsilon(s)}{N(s)} = \frac{-G_2H}{1+G_1G_2H}$</p>
<p>计算方法:</p>
<ul>
<li>利用干扰偏差传递函数</li>
</ul>
<p>增大 $G_1$ 的增益或是添加积分环节可以消除干扰误差.</p>
<hr>
<p>系统的型次</p>
<p>重写系统开环传递函数 $G(s)H(s) = \frac{K(\tau_1s+1)(\tau_2s+1)…}{s^\lambda(T_1s+1)(T_2s+1)…}$</p>
<p>$\lambda=0/1/2:$ 0 / I / II 型系统</p>
<ul>
<li><p>静态位置误差系数 </p>
<p>$K_p = \lim_{s\rightarrow0}G(s)H(s)=G(0)H(0)$</p>
<p>对<strong>单位阶跃输入</strong>, 稳态偏差 $\epsilon_{ss}=\lim_{s\rightarrow0}s\cdot \frac{1}{1+G(s)H(s)} \frac{1}{s} = \frac{1}{1+G(0)H(0)} = \frac{1}{1+K_p}$</p>
<p>0  型系统 $K_p = K,~\epsilon_{ss}=\frac{1}{1+K}$</p>
<p>I,II型系统 $K_p = \infty,~\epsilon_{ss}=\frac{1}{1+\infty}=0$</p>
</li>
<li><p>静态速度误差系数</p>
<p>$K_v = \lim_{s\rightarrow0}s\cdot G(s)H(s)$</p>
<p>对<strong>单位斜坡输入</strong>, 稳态偏差 $\epsilon_{ss}=\lim_{s\rightarrow0}s\cdot \frac{1}{1+G(s)H(s)} \frac{1}{s^2} = \lim_{s\rightarrow0}\frac{1}{sG(s)H(s)} = \frac{1}{K_v}$</p>
<p>0 型系统 $K_v = 0,~\epsilon_{ss}=\infty$</p>
<p>I  型系统 $K_v = K,~\epsilon_{ss}=\frac{1}{K}$</p>
<p>II 型系统 $K_v = \infty,~\epsilon_{ss}=0$</p>
</li>
<li><p>静态加速度误差系数</p>
<p>$K_a = \lim_{s\rightarrow0}s^2\cdot G(s)H(s)$</p>
<p>对<strong>单位加速度输入</strong>, 稳态偏差 $\epsilon_{ss}=\lim_{s\rightarrow0}s\cdot \frac{1}{1+G(s)H(s)} \frac{1}{s^3} = \lim_{s\rightarrow0}\frac{1}{s^2G(s)H(s)} = \frac{1}{K_a}$</p>
<p>0 型系统 $K_v = 0,~\epsilon_{ss}=\infty$</p>
<p>I  型系统 $K_v = 0,~\epsilon_{ss}=\infty$</p>
<p>II 型系统 $K_v = K,~\epsilon_{ss}=\frac{1}{K}$</p>
<p>| ? | 单位阶跃 | 单位斜坡 | 单位加速度 |<br>| :——: | :——: | :——: | :——: |<br>| 0 型 | $\frac{1}{1+K}$ | $\infty$ | $\infty$ |<br>| I 型 | 0 | $\frac{1}{K}$ | $\infty$ |<br>| II 型 | 0 | 0 | $\frac{1}{K}$ |</p>
</li>
</ul>
<p>增大 $K$, 可<strong>减小</strong>输入引起的稳态误差</p>
<p>提高型次, 可以<strong>消除</strong>输入引起的稳态误差</p>
<h1 id="Lecture-X-2"><a href="#Lecture-X-2" class="headerlink" title="Lecture X+2"></a>Lecture X+2</h1><p>BIBO 稳定性</p>
<p>Bounded Input Bounded Output?</p>
<p>$|r(t)|_{t\rightarrow\infty} &lt; \infty \rightarrow |y(t)|_{t\rightarrow\infty} &lt; \infty$</p>
<p>系统固有属性, 与输入无关.</p>
<p>稳定充要条件: 所有闭环极点都在左半平面.</p>
<p>若虚轴有极点, 则临界稳定</p>
<p>若右平面有极点, 则不稳定</p>
]]></content>
      <categories>
        <category>lecture notes</category>
      </categories>
  </entry>
  <entry>
    <title>DSP note</title>
    <url>/2021/09/13/DSP_note/</url>
    <content><![CDATA[<h1 id="Lecture-1"><a href="#Lecture-1" class="headerlink" title="Lecture 1"></a>Lecture 1</h1><p>信号是信息的载体, 信号 ~ 函数</p>
<ul>
<li><p>时间为自变量</p>
<ul>
<li><p>连续信号 $x(t)$​ -&gt; 模拟信号: 取值也连续​</p>
</li>
<li><p>离散信号 $x[n]$​ -&gt; 数字信号: 取值也离散</p>
</li>
</ul>
</li>
</ul>
<p>模拟信号 </p>
<p>—&gt;(信号采样) 抽样信号, $t$​ 由连续变为离散 </p>
<p>—&gt;(数值量化)  数字信号, 取值由连续变为离散, 只有一些固定点上有取值 (000, 001, 010, …)</p>
<p>—&gt;(零阶保持)  量化信号, $t$​​​ 由离散恢复为连续, 取值依然离散 (把点用线段连起来?)</p>
<p>—&gt;(低通滤波)  模拟信号, 取值恢复为连续</p>
<p>确定信号: 信号随时间变化服从确定规律, 能够以确定时间函数表示.</p>
<p>系统的输入(激励), 输出(响应)都是信号(函数), 对信号进行加工, 变换.</p>
<p>FFT: Fast Fourier Transformation</p>
<p>时域: 以时间为自变量描述信号和系统</p>
<p>空域: 以空间为自变量描述信号和系统 (图片)</p>
<p>频域: 以频率为自变量描述信号和系统. 如果不以频率为基本单位, 也成为变换域.</p>
<p>频谱: 信号的频域表示, 描述信号各个频率分量的幅度和相位.</p>
<p>滤波器: 一种信号处理系统, 实现按照一定目的对信号的变换/过滤 (过滤频率)</p>
<p>时域 ~~ 傅里叶变换 ~~ 频域 (从频率角度提取特征)</p>
]]></content>
      <categories>
        <category>lecture notes</category>
      </categories>
  </entry>
  <entry>
    <title>HSEA note</title>
    <url>/2021/09/13/HSEA_note/</url>
    <content><![CDATA[<h1 id="Lecture-1"><a href="#Lecture-1" class="headerlink" title="Lecture 1"></a>Lecture 1</h1><p>A search problem</p>
<ul>
<li>initial state (what about state space?)</li>
<li>actions</li>
<li>transition model</li>
<li>foal test</li>
<li>path cost</li>
</ul>
<p>Solution: a path</p>
<hr>
<p><strong>complexity</strong></p>
]]></content>
      <categories>
        <category>lecture notes</category>
      </categories>
  </entry>
  <entry>
    <title>初试类魂游戏</title>
    <url>/2021/09/14/NIOH/</url>
    <content><![CDATA[<h3 id="9-15"><a href="#9-15" class="headerlink" title="9.15"></a>9.15</h3><p>昨天的塔顶两阶段boss一遍过.</p>
<h3 id="9-14"><a href="#9-14" class="headerlink" title="9.14"></a>9.14</h3><p>今天 EPIC 送了仁王, 一开始觉得很好玩, 小兵两刀一个, 后来遇到盔甲兵, 死了快十次, 终于打过了, 来到一个塔顶打boss, 几刀把他砍翻了, 结果黑化来个二阶段, 一刀把我砍死了, 又要重新砍小兵, 砍盔甲兵…</p>
<p>不得不说类魂游戏确实很有魅力, 身处压抑而宏大的氛围, 慢慢探索, 慢慢进步, 重复着观察-&gt;砍一刀-&gt;闪避-&gt;砍一刀-&gt;闪避-&gt;贪刀-&gt;被一刀砍死的过程, 让玩家的神经处于高度紧绷而亢奋的状态, 非常上头. 然而说难听的就是找虐?? 打了大半天, 一点失误直接白给?</p>
<p>算了, 以后有时间再来挑战吧.</p>
]]></content>
      <categories>
        <category>casual writing</category>
      </categories>
  </entry>
  <entry>
    <title>DSPC note</title>
    <url>/2021/09/26/PC_note/</url>
    <content><![CDATA[<h2 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h2><ul>
<li>B, Bridge, 存储器总线和I/O总线间的接口</li>
<li>DIR, Cache Directory, 高速缓存目录</li>
<li>IOB, IO Bus, I/O 总线</li>
<li>LD, Local Dosk, 本地磁盘</li>
<li>MB, Memory Bus, 存储器总线</li>
<li>NIC, Network Interface Circuitry, 网络接口电路</li>
<li>P/C, Microprocessor and Cache, 微处理器和高速缓存</li>
<li>VP, Vector Processor, 向量处理器</li>
<li>SM, Shared Memory, 共享存储器</li>
<li>LM, Local Memory, 本地存储器</li>
</ul>
<p>大型并行计算机系统有</p>
<ul>
<li><p>SIMD, Single-Instruction Multiple-Data, 单指令多数据流</p>
</li>
<li><p>PVP, Parallel Vector Processor, 并行向量处理机</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/2021093001.png" style="zoom: 50%;" /></p>
</li>
<li><p>SMP, Symmetric Multiprocessor, 对称多处理机</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/2021093002.png" style="zoom:50%;" /></p>
<ul>
<li>每个处理器可同等地访问共享存储器, IO设备和操作系统服务</li>
<li>单地址空间, OS 容易调度</li>
<li>处理器不能太多</li>
<li>总线和交叉开关互连一旦做成也难以扩展</li>
</ul>
</li>
<li><p>MPP, Massively Parallel Processor, 大规模并行处理机</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/2021093003.png" style="zoom: 67%;" /></p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/2021093010.png" style="zoom: 67%;" /></p>
<ul>
<li>能扩放至上万个处理器</li>
<li>程序由多个进程组成, 每个都有其私有地址空间, 进程间采用传递消息机制相互作用</li>
<li>高带宽低延迟互连网络</li>
</ul>
</li>
<li><p>DSM, Distributed Shared Memory, 分布共享存储多处理机</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/2021093004.png" style="zoom: 67%;" /></p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/2021093011.png" style="zoom: 67%;" /></p>
<ul>
<li>DIR 支持分布 cache 的一致性</li>
<li>与 SMP 相比, 物理上有分布在各节点中的局存, 形成共享存储器</li>
<li>单一地址编程空间, 比 MPP 编程容易</li>
</ul>
</li>
<li><p>COW, Cluster of Workstations, 工作站机群</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/2021093005.png" style="zoom:67%;" /></p>
<ul>
<li>每个节点都是一个完整的工作站 (PC, SMP)</li>
<li>标准网络 (MPP DSM 为定制网络)</li>
<li>网络接口松散 (MPP紧耦合, 网络连到节点 MB)</li>
<li>每个节点都有完整操作系统</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/2021093006.png" style="zoom: 67%;" /></p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/2021093007.png" style="zoom:67%;" /></p>
<p>访存模型</p>
<ul>
<li>UMA, Uniform Memory Access, 均匀存储访问<ul>
<li>物理存储器被所有处理器均匀共享</li>
<li>处理器访问任何存储单元的时间均相同</li>
<li>每台处理器可带私有 cache</li>
</ul>
</li>
<li>NUMA, NonUMA, 非均匀存储访问<ul>
<li>被共享的存储器物理上分布在所有处理器中</li>
<li>所有本地存储器的集合构成全局地址空间</li>
<li>处理器访问存储单元的时间不同</li>
</ul>
</li>
<li>COMA, Cache Only MA, 全高速缓存存储访问<ul>
<li>NUMA 的一个特例</li>
<li>全部 cache 组成全局地址空间</li>
</ul>
</li>
<li>CC-NUMA, Coherent-Cache NUMA, 高速缓存一致性非均匀访问<ul>
<li>将一些 SMP 作为单节点彼此连接</li>
</ul>
</li>
<li>NORMA, No-Remote MA, 非远程存储访问<ul>
<li>所有存储器都是私有的, 仅由其处理器访问</li>
</ul>
</li>
</ul>
<h2 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h2><h3 id="静态互连网络"><a href="#静态互连网络" class="headerlink" title="静态互连网络"></a>静态互连网络</h3><p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/2021093008.png" style="zoom: 80%;" /></p>
<h3 id="动态互连网络"><a href="#动态互连网络" class="headerlink" title="动态互连网络"></a>动态互连网络</h3><p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/2021093009.png" style="zoom: 80%;" /></p>
<h2 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h2><p>第一章</p>
<h2 id="第四章"><a href="#第四章" class="headerlink" title="第四章"></a>第四章</h2><h3 id="加速比"><a href="#加速比" class="headerlink" title="加速比"></a>加速比</h3><p>并行系统的加速(比): 对于一个给定的应用, 并行程序的执行速度相对于串行程序的执行速度加快了多少倍.</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">$p$</th>
<th style="text-align:center">处理器数</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$W = W_{series} + W_{parallel}$</td>
<td style="text-align:center">问题规模</td>
</tr>
<tr>
<td style="text-align:center">$f = W_s / W$</td>
<td style="text-align:center">串行分量比例</td>
</tr>
<tr>
<td style="text-align:center">$1 - f$</td>
<td style="text-align:center">并行分量比例</td>
</tr>
<tr>
<td style="text-align:center">$T_s$</td>
<td style="text-align:center">串行执行时间</td>
</tr>
<tr>
<td style="text-align:center">$T_p$</td>
<td style="text-align:center">并行执行时间</td>
</tr>
<tr>
<td style="text-align:center">$S$</td>
<td style="text-align:center">加速比</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Amdahl-定律"><a href="#Amdahl-定律" class="headerlink" title="Amdahl 定律"></a>Amdahl 定律</h4><p>固定计算负载, 提高速度, 可增大 $p$​</p>
<p>$S = \frac{W_s+W_p}{W_s+W_p/p} =\frac{ f + (1-f)}{f+\frac{1-f}{p}} = \frac{p}{1+f(p-1)} \rightarrow\frac{1}{f}$​</p>
<p>即假设 $f=0.5$, 即使 $p$ 无限大, 加速上限为 2 倍.</p>
<p>若考虑额外开销 $W_o$</p>
<p>$S = \frac{W_s+W_p}{W_s+W_p/p+W_o} = \frac{p}{1+f(p-1)+W_op/W} \rightarrow\frac{1}{f+W_o/W}$</p>
<p>串行分量和并行额外开销越大, 加速越小</p>
<h4 id="Gustafson-定律"><a href="#Gustafson-定律" class="headerlink" title="Gustafson 定律"></a>Gustafson 定律</h4><p>可扩放问题. 提高精度, 增大计算量(问题规模). 认为增多处理器必须相应地增大问题规模才有意义.</p>
<p>$S’ = \frac{W_s+pW_p}{W_s+pW_p/p} =p-f(p-1)$</p>
<p>当 $p$ 充分大, $S’$ 与 $p$ 呈线性关系, 斜率为 $1-f$</p>
<p>若考虑额外开销 $W_o$</p>
<p>$S’ = \frac{W_s+pW_p}{W_s+pW_p/p+W_o} =\frac{f+p(1-f)}{1+W_o / W}$</p>
<h4 id="Sun-and-Ni-定律"><a href="#Sun-and-Ni-定律" class="headerlink" title="Sun and Ni 定律"></a>Sun and Ni 定律</h4><p>受限于存储器. 认为只要存储许可, 应尽量增大问题规模.</p>
<p>设单节点使用全部存储 $M$ 求解 $W = fW +(1-f)W$.</p>
<p>$p$ 个节点存储为 $pM$, 设 $G(p)$ 为存储增加到 $p$ 倍时负载的增加量, 则 $W = fW + (1-f)G(p)W$</p>
<p>$S’’ = \frac{fW + (1-f)G(p)W}{fW + (1-f)G(p)W /p} = \frac{f + (1-f)G(p)}{f + (1-f)G(p) /p}$</p>
<p>若考虑额外开销 $W_o$</p>
<p>$S’’ =\frac{f + (1-f)G(p)}{f + (1-f)G(p) /p+W_o / W}$​</p>
<ul>
<li>当 $G(p)$ = 1, 变为 Amdahl</li>
<li>当 $G(p)$​ = $p$, 变为 Gustafson</li>
</ul>
<hr>
<p>一般 $\frac{p}{\log p} \le S \le p$</p>
<h3 id="可扩放性"><a href="#可扩放性" class="headerlink" title="可扩放性"></a>可扩放性</h3><p>区别于加速比的另一种性能指标: 性能随 $p$ 的增加而按比例提高的能力.</p>
<p>衡量程序能否有效利用扩充的处理器.</p>
<h4 id="等效率度量标准"><a href="#等效率度量标准" class="headerlink" title="等效率度量标准"></a>等效率度量标准</h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">$t_e^i$</th>
<th style="text-align:center">第 $i$ 个处理器的有用计算时间</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">$t_o^i$</td>
<td style="text-align:center">第 $i$ 个处理器的额外开销时间</td>
</tr>
<tr>
<td style="text-align:center">$T_p = t_e^i + t_o^i = (T_e + T_o) / p$</td>
<td style="text-align:center">处理器并行算法运行时间</td>
</tr>
<tr>
<td style="text-align:center">$W = T_e = \sum\limits_{i=0} ^{p-1} t_e^i$</td>
<td style="text-align:center">问题规模, 工作负载, 最佳串行算法所完成计算量</td>
</tr>
<tr>
<td style="text-align:center">$S = \frac{T_e}{T_p} = \frac{p}{1+\frac{T_o}{W}}$</td>
<td style="text-align:center">加速</td>
</tr>
<tr>
<td style="text-align:center">$E=\frac{S}{p} = \frac{1}{1+\frac{T_o}{W}}$</td>
<td style="text-align:center">效率</td>
</tr>
</tbody>
</table>
</div>
<p>为了维持 $E$​ 不变, 需在增大 $p$​ 的同时增大 $W = f_E(p)$​</p>
<p>若 $W$ 随 $p$ 线性或亚线性增长, 则算法具有良好的可扩放性.</p>
<p>若 $W$ 随 $p$ 指数等快速增长, 则算法不可扩放.</p>
<h4 id="等速度度量标准"><a href="#等速度度量标准" class="headerlink" title="等速度度量标准"></a>等速度度量标准</h4><p>速度能以处理器数的增加而线性增加(平均速度不变), 则可扩放性好.</p>
<p>速度 $V = W / T$</p>
<p>平均速度 $\bar{V} = \frac{V}{p} = \frac{W}{pT}$​</p>
<p>定义标准 $\Psi(p,p’) = \frac{W/p}{W’/p’}\in(0,1)$​​, 越大可扩放性越好.</p>
<p>若平均速度保持不变, $\Psi = T/T’$</p>
<p>$\Psi(1,p’) = \frac{T_1}{T_p’}=\frac{W}{W’/p’} = \frac{解决工作量为 W 的问题所需串行时间}{解决工作量为 W 的问题所需并行时间}$</p>
<h4 id="平均延迟度量标准"><a href="#平均延迟度量标准" class="headerlink" title="平均延迟度量标准"></a>平均延迟度量标准</h4><p>$T_i$: $p_i$ 的执行时间, 包括运行时导致的延迟 $L_i$</p>
<p>定义系统平均延迟时间 $\bar{L}(W,p) = \sum\limits_{i=1}^p(T_{para} - T_i + L_i) / p = T_{para} - T_{series} / p$</p>
<p>定义标准 $\Phi(E,p,p’)=\frac{$\bar{L}(W,p)}{$\bar{L}(W’,p’)} \in (0,1)$, 越大可扩放性越好.</p>
<h2 id="第五章"><a href="#第五章" class="headerlink" title="第五章"></a>第五章</h2><p>对比于串行计算的冯诺依曼模型, 并行计算有以下模型</p>
<h3 id="PRAM"><a href="#PRAM" class="headerlink" title="PRAM"></a>PRAM</h3><p>Parallel Random Access Machine</p>
<p>并行随机存取机器</p>
<p>共享存储的 SIMD 模型</p>
<p>在任何时刻各处理器均可通过共享存储单元相互交换数据</p>
<h4 id="PRAM-EREW"><a href="#PRAM-EREW" class="headerlink" title="PRAM-EREW"></a>PRAM-EREW</h4><p>PRAM Exclusive-Read and Exclusive-Write</p>
<p>不允许同时读和同时写的 PRAM</p>
<h4 id="PRAM-CREW"><a href="#PRAM-CREW" class="headerlink" title="PRAM-CREW"></a>PRAM-CREW</h4><p>PRAM Concurrent-Read and Exclusive-Write</p>
<p>允许同时读和同时写的 PRAM</p>
<h4 id="PRAM-CRCW"><a href="#PRAM-CRCW" class="headerlink" title="PRAM-CRCW"></a>PRAM-CRCW</h4><p>PRAM Concurrent-Read and Concurrent-Write</p>
<p>允许同时读和同时写的 PRAM</p>
<p>然而允许同时写不现实</p>
<ul>
<li>只允许同时写相同的数        CPRAM-CRCW Common</li>
<li>只允许最优先的处理器先写 PPRAM-CRCW Priority</li>
<li>允许任意处理器自由写         APRAM-CRCW Arbitrary</li>
</ul>
<p>$T_{EREW} \ge T_{CREW} \ge T_{CRCW} $</p>
<p>$T_{EREW} = O (T_{CREW}) \cdot \log p = O (T_{CRCW}) \cdot \log p$</p>
<p>EREW 是最慢的</p>
<h3 id="APRAM"><a href="#APRAM" class="headerlink" title="APRAM"></a>APRAM</h3><p>异步 Asynchronous PRAM</p>
<p>每个处理器都有局存, 局部时钟和局部程序. 通过共享全局存储通信.</p>
<p>无全局时钟, 各处理器<strong>异步独立</strong>执行各自指令</p>
<p>时间依赖关系需明确在各程序中加入<strong>同步路障</strong></p>
<p>指令:</p>
<ul>
<li>全局读: 全局存储-&gt;读入-&gt;局存</li>
<li>局部操作: 计算, 改写局存</li>
<li>全局写: 局存-&gt;写入-&gt;全局存储</li>
<li>同步: 等待别的处理器到达</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">p1</th>
<th style="text-align:center">p2</th>
<th style="text-align:center">pn</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">phase1</td>
<td style="text-align:center">read x1</td>
<td style="text-align:center">read x3</td>
<td style="text-align:center">read xn</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">read x2</td>
<td style="text-align:center">*</td>
<td style="text-align:center">*</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">*</td>
<td style="text-align:center">write to B</td>
<td style="text-align:center">*</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">write to A</td>
<td style="text-align:center">write to C</td>
<td style="text-align:center">write to D</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">同步障</td>
<td style="text-align:center">同步障</td>
<td style="text-align:center">同步障</td>
</tr>
<tr>
<td style="text-align:center">phase2</td>
<td style="text-align:center">read B</td>
<td style="text-align:center">read A</td>
<td style="text-align:center">read C</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center">同步障</td>
<td style="text-align:center">同步障</td>
<td style="text-align:center">同步障</td>
</tr>
<tr>
<td style="text-align:center">phase3</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
</tr>
</tbody>
</table>
</div>
<p>$T = \Sigma ~每个~phase~的小霸王时间 + 同步障时间~ B \times 同步障次数 $</p>
<h3 id="BSP"><a href="#BSP" class="headerlink" title="BSP"></a>BSP</h3><p>Bulk Synchronous Parallel</p>
<p>计算由一系列用全局同步分开, 周期为 L 的超级步组成</p>
<p>各超级步中每个处理器执行局部计算, 并通过选路器接发信息. 然后作一全局检查看是否所有处理器都已完成.</p>
<p>分布存储的 MIMD</p>
]]></content>
      <categories>
        <category>lecture notes</category>
      </categories>
  </entry>
  <entry>
    <title>双系统配置</title>
    <url>/2021/09/14/Window10+Ubuntu18.04configuration/</url>
    <content><![CDATA[<h2 id="Windows-10"><a href="#Windows-10" class="headerlink" title="Windows 10"></a>Windows 10</h2><h3 id="下载-Ubuntu-18-04-镜像文件"><a href="#下载-Ubuntu-18-04-镜像文件" class="headerlink" title="下载 Ubuntu 18.04 镜像文件"></a>下载 Ubuntu 18.04 镜像文件</h3><p>打开 <a href="https://old-releases.ubuntu.com/releases/18.04/">Ubuntu 官网</a>, 点击下载 <code>ubuntu-18.04-desktop-amd64.iso</code></p>
<h3 id="准备磁盘空间"><a href="#准备磁盘空间" class="headerlink" title="准备磁盘空间"></a>准备磁盘空间</h3><p>右键 ‘开始’, 点击 ‘磁盘管理’, 通过对C/D盘等 ‘压缩卷’ 获得至少 40 GB 的 ‘未分配’ 空间.</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021100305.jpg" style="zoom:10%;" /></p>
<h3 id="制作启动盘"><a href="#制作启动盘" class="headerlink" title="制作启动盘"></a>制作启动盘</h3><p>插入 U 盘.</p>
<p>下载安装打开 <a href="https://cn.ultraiso.net/xiazai.html">ultraISO</a>, 点击 ‘文件’, 打开 <code>ubuntu-18.04-desktop-amd64.iso</code>, 点击 ‘启动’, ‘写入硬盘映像’, 点击 ‘写入’.</p>
<p>完成后关机.</p>
<h2 id="BIOS"><a href="#BIOS" class="headerlink" title="BIOS"></a>BIOS</h2><p>…</p>
<hr>
<p>不想搞了, 用SSH连组里的服务器了.</p>
]]></content>
      <categories>
        <category>configuration</category>
      </categories>
  </entry>
  <entry>
    <title>戴小姐披萨店</title>
    <url>/2021/10/03/daixiaojie/</url>
    <content><![CDATA[<p>2021.10.3</p>
<h4 id="菜品"><a href="#菜品" class="headerlink" title="菜品"></a>菜品</h4><p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021100301.jpg" style="zoom:10%;" /></p>
<center>薯条 12元</center>

<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021100302.jpg" style="zoom:10%;" /></p>
<center>海苔鳗鱼披萨 60元</center>

<center>总价72元 人均36元</center>

<h4 id="餐厅环境"><a href="#餐厅环境" class="headerlink" title="餐厅环境"></a>餐厅环境</h4><p>装修风格不错, 明亮整洁, 但是在一楼用餐时会有小虫子</p>
<h4 id="用餐时间"><a href="#用餐时间" class="headerlink" title="用餐时间"></a>用餐时间</h4><p>没有排队, 上菜也很快.</p>
<h4 id="餐厅位置"><a href="#餐厅位置" class="headerlink" title="餐厅位置"></a>餐厅位置</h4><p>南京市栖霞区仙林大道163号南大和园</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021100304.jpg" style="zoom:20%;" /></p>
]]></content>
      <categories>
        <category>Restaurants</category>
      </categories>
  </entry>
  <entry>
    <title>花津浦</title>
    <url>/2021/10/01/huajinpu/</url>
    <content><![CDATA[<p>2021.10.1</p>
<h4 id="菜品"><a href="#菜品" class="headerlink" title="菜品"></a>菜品</h4><p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021100102.jpg" style="zoom:10%;" /></p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021100108.jpg" style="zoom:10%;" /></p>
<center>烤切片牛舌 38元</center>

<center>烤鸡腿肉 9*2元</center>

<center>原味烤牛肉 29元</center>

<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021100107.jpg" style="zoom:10%;" /></p>
<center>冰淇淋烤布蕾 28元</center>

<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021100103.jpg" style="zoom:10%;" /></p>
<center>烤羊肉串 6*2元</center>

<center>生菜 4元</center>

<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021100109.jpg" style="zoom:10%;" /></p>
<center>拌翡翠海藻 10元</center>

<center>总价140元 人均70元 非节假日美团有100-20券</center>

<h4 id="餐厅环境"><a href="#餐厅环境" class="headerlink" title="餐厅环境"></a>餐厅环境</h4><p>比较嘈杂, 布局还可以, 能看到熟菜制作.</p>
<h4 id="用餐时间"><a href="#用餐时间" class="headerlink" title="用餐时间"></a>用餐时间</h4><p>没有排队, 上菜也很快.</p>
<h4 id="餐厅位置"><a href="#餐厅位置" class="headerlink" title="餐厅位置"></a>餐厅位置</h4><p>南京市栖霞区学津路与杉湖西路交叉口东北角金鹰湖滨天地2期3F</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021100104.jpg" style="zoom:15%;" /></p>
<p>国庆快乐.</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/master/2021100105.jpg" style="zoom:20%;" /></p>
]]></content>
      <categories>
        <category>Restaurants</category>
      </categories>
  </entry>
  <entry>
    <title>带啥?</title>
    <url>/2021/09/20/luggage/</url>
    <content><![CDATA[<h3 id="2021-9-回校"><a href="#2021-9-回校" class="headerlink" title="2021.9 回校"></a>2021.9 回校</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">东西</th>
<th style="text-align:center">带了吗?</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">身份证</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">驾驶证</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">手机</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">手机充电器</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">校卡</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">银行卡*2</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">家钥匙</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">雨伞</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">小包纸巾</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">无线耳机</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">U盘</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">电脑</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">电脑充电器</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">鼠标</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">鼠标垫</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">耳机</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">耳机盒子</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">充电宝</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">键盘</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">大鼠标垫</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">转接器</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">坚果</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">月饼</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">衣服</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">拉力器</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">口罩</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">眼镜盒</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">防晒霜</td>
<td style="text-align:center">0</td>
</tr>
<tr>
<td style="text-align:center">洗面奶</td>
<td style="text-align:center">1</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>casual writing</category>
      </categories>
  </entry>
  <entry>
    <title>山水一方</title>
    <url>/2021/09/20/shanshuiyifang/</url>
    <content><![CDATA[<p>2021.9.20</p>
<h4 id="菜品"><a href="#菜品" class="headerlink" title="菜品"></a>菜品</h4><p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21092003.jpg" style="zoom:10%;" /></p>
<center>雪山杨枝甘露 15元</center>

<blockquote>
<p>虚假的雪山: 香<del>菜</del>草味冰淇淋</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21092004.jpg" style="zoom:10%;" /></p>
<center>杨枝甘露 12元</center>

<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21092006.jpg" style="zoom:15%;" /></p>
<center>芒果绵绵冰 26元</center>

<blockquote>
<p>真实的雪山: 绵软的口感, 甜甜的冰淇淋</p>
</blockquote>
<center>总价 15 + 12 + 26 = 53 元, 加美团 50 - 10 券 43 元, 人均 14.3 元.</center>

<h4 id="餐厅环境"><a href="#餐厅环境" class="headerlink" title="餐厅环境"></a>餐厅环境</h4><p>店面较小, 生意火爆, 有一点挤.</p>
<h4 id="用餐时间"><a href="#用餐时间" class="headerlink" title="用餐时间"></a>用餐时间</h4><p>印象中等了10分钟左右.</p>
<h4 id="餐厅位置"><a href="#餐厅位置" class="headerlink" title="餐厅位置"></a>餐厅位置</h4><p>肇庆市端州区沙墩路二号第一栋首层第4卡商铺</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21092008.jpg" style="zoom:50%;" /></p>
<hr>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21092002.jpg" style="zoom:7%;" /></p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21092001.jpg" style="zoom:15%;" /></p>
<p>中秋快乐.</p>
]]></content>
      <categories>
        <category>Restaurants</category>
      </categories>
  </entry>
  <entry>
    <title>高中摘抄</title>
    <url>/2019/09/01/zhaichao/</url>
    <content><![CDATA[<h2 id="2019"><a href="#2019" class="headerlink" title="2019"></a>2019</h2><h3 id="9-7"><a href="#9-7" class="headerlink" title="9.7"></a>9.7</h3><p>汗牛充栋: 形容书籍多, 不能形容其他东西</p>
<p>耳提面命: 用于长辈对晚辈</p>
<p>三令五申: 用于上级对下级</p>
<p>玩岁愒kai\日: 指贪图安逸, 荒废岁月</p>
<p>乌衣子弟: 借指出身名门贵族的人</p>
<p>意兴阑珊: 指意趣, 兴致低落将尽</p>
<p>羽扇纶巾: 形容名士的装束, 后泛指文人谋士的潇洒风度</p>
<p>韫匵du?而藏: 把美玉藏在匣子里, 等待高价出售, 比喻怀才待用或有才而不用</p>
<p>燃犀温峤: 指人洞察力强</p>
<p>添砖加瓦: 比喻尽微薄之力, 做一点贡献</p>
<hr>
<p>大海不会馈赠那些急功近利的人. 为功利而来, 不仅透露了来者的焦躁与贪婪, 还有他信仰的缺失. 耐心, 耐心, 耐心, 这是大海教给我们的, 人应如海滩一样, 倒空自己, 虚怀无欲, 等待大海的礼物. —安妮 $\cdot$ 林登伯格 </p>
<h3 id="9-6"><a href="#9-6" class="headerlink" title="9.6"></a>9.6</h3><p>野有饿殍: 野外有饿死的人, 形容兵荒马乱或凶年饥岁的悲惨景象</p>
<p>苦心孤诣: 刻苦钻研探索, 达到某种独到的境界</p>
<p>惨淡经营: 惨淡, 尽心思虑, 经营, 指规划或构思. 原指艺术创作过程中苦心构思, 精心布局, 后也形容苦心谋划并从事某事或某项事业</p>
<p>筚路蓝缕: 驾着柴车, 穿着破衣服, 形容创业的艰难</p>
<p>隔靴搔痒: 比喻说话, 做事, 写作等不中肯, 没有抓住关键, 也比喻不解决实际问题</p>
<p>喷薄欲出: 形容水涌起或太阳初升时霞光喷涌四射的样子</p>
<p>袍笏hu\登场: 穿上官服, 拿着笏板登场了</p>
<p>衾qin-影无惭: 形容光明磊落, 即使独处也很坦然</p>
<p>色厉内荏: 形容外表强硬, 内心怯弱</p>
<p>搔首踟chi?蹰chu?: 形容焦灼不安的样子</p>
<hr>
<p>青春像一把刀子, 锋利敏感, 而生活像另一把刀子, 厚重敦实, 当青春和生活这两把刀子对削时, 青春这把刀子就会慢慢卷刃, 而人也在生活中渐渐成熟. —吕乐 十三棵泡桐</p>
<h3 id="9-5"><a href="#9-5" class="headerlink" title="9.5"></a>9.5</h3><p>日长一线: 指冬至后白昼渐长</p>
<p>不经之谈: 形容不合道理, 荒唐无根据的话. 经: 通常的道理. 贬义</p>
<p>差强人意: 表示还能够使人满意</p>
<p>毫发不爽: 一点差错或失误也没有, 形容非常准确</p>
<p>讳莫如深: 形容将事情紧紧隐瞒, 不让人知道</p>
<p>蕙心纨质: 形容女子姿质美好, 心灵纯洁</p>
<p>昏定晨省: 旧指子女服侍双亲的日常礼节</p>
<p>宿学旧儒: 指年老博学的读书人</p>
<hr>
<p>一个大花园里有各种各样的鲜花, 你不一定是最大最艳的那一朵, 但是你是朵”小清新”, 你有你的价值, 也必然有人会发现你的价值.</p>
<h3 id="9-4"><a href="#9-4" class="headerlink" title="9.4"></a>9.4</h3><p>穷酸饿醋: 旧时讥称贫寒, 迂腐的读书人</p>
<p>睚ya?眦zi\必报: 连瞪过自己一眼那样的小怨小恨也要报复. 形容气量极其狭小</p>
<p>一曝十寒: 比喻做事缺少恒心, 时而用功, 时而懈怠</p>
<p>薏苡明珠: 薏苡, 草本植物, 形似珍珠. 把薏苡错当明珠. 指被人诽谤而蒙冤受屈, 或指蓄意歪曲事实, 陷害他人</p>
<p>意在笔先: 指书写绘画或写文章时先构思成熟, 然后下笔</p>
<p>引足救经: 要去救上吊的人, 却去拉他的脚. 比喻方法错误, 动机与效果相反</p>
<p>引虎自卫: 比喻把危险势力当靠山, 将会自招祸患</p>
<p>众毛攒裘: 将许多碎片皮毛积聚起来, 可以缝制成皮衣, 比喻积少成多</p>
<p>亦步亦趋: 别人慢走就慢走, 别人快走就快走, 原比喻仅仅效法跟随, 后多比喻自己没有主见, 处处模仿, 追随别人</p>
<p>胸中甲兵: 比喻人有善于用兵的韬晦</p>
<hr>
<p>我读的书愈多, 就愈亲近世界, 愈明了生活的意义, 愈觉得生活的重要. —高尔基</p>
<p>笨蛋自以为聪明, 聪明人才知道自己是笨蛋. —莎士比亚</p>
<h3 id="9-3"><a href="#9-3" class="headerlink" title="9.3"></a>9.3</h3><p>酒池肉林: 原指商代暴君纣王荒淫无度, 后用来形容酒肉丰盛, 筵席奢华</p>
<p>口诛笔伐: 用言语或文字对敌对者的罪行进行谴责和声讨</p>
<p>扣人心弦: 形容语言或表演富于感染力, 激动人心</p>
<p>满面春风: 比喻人和蔼, 喜悦或得意的神色</p>
<p>因材施教: 针对受教育者的能力, 性格, 志趣等具体情况, 采用不同的教育方法</p>
<p>银河倒泻: 形容瀑布的壮丽景色或下大雨的情景</p>
<p>银钩虿chai\尾: 比喻书法遒劲有力</p>
<p>见骥一毛: 比喻只对事物局部有所了解</p>
<p>胼手胼足: 形容受尽肌肤之劳</p>
<p>否pi极泰来: 坏到了尽头就要转好</p>
<hr>
<p>真理惟一可靠的标准就是永远自相符合. —欧文</p>
<p>世界上一成不变的东西, 只有”任何事物都是在不断变化的”这条真理. —斯里兰卡</p>
<hr>
<p>作者还说: “一个逻辑学家不需要亲眼看见或听说过大西洋或是尼亚加拉大瀑布就能从一滴水推测出它有无存在的可能. 因此, 生活就像是一条巨大的链条, 只要我们看到了其中一环, 整个链条的本质就能一目了然了. 像所有学科一样, 推断分析学也只有经过长期, 耐心的研究才能掌握; 而人们用了一生的精力也未必能在这方面达到登封的境界……” —福尔摩斯探案集</p>
<h3 id="9-2"><a href="#9-2" class="headerlink" title="9.2"></a>9.2</h3><p>弹冠相庆: 旧官场中一人当了官, 同伙就互相庆贺将有官可做. 贬义, 指坏人得意的样子</p>
<p>久假不归: 长期地借用, 不归还. 假: 借</p>
<p>不绝如缕: 形容局势危急或声音细微悠长</p>
<p>七月流火: 指天气逐渐凉爽. 火: 火星. 火星西行, 意味天气转凉</p>
<p>敬谢不敏: 表示对某事不愿接受或能力不够, 只好谢绝</p>
<hr>
<p>我是一株百合, 不是一株野草. 惟一能证明我是百合的, 就是开出一朵花.</p>
<p>如果你有两块面包, 请你用其中一块去换一朵芬芳的水仙花. —穆罕默德</p>
<h3 id="9-1"><a href="#9-1" class="headerlink" title="9.1"></a>9.1</h3><p>明日黄花: 比喻过时或无意义的事物</p>
<p>火中取栗: 比喻被别人利用去干冒险的事, 付出了代价而得不到好处. 贬义</p>
<p>万人空巷: 成千上万的人涌向某处, 使里巷冷落, 形容庆祝, 欢迎等盛况</p>
<p>不刊之论: 指正确的不可修改的言论. 刊: 消除, 古代把字写于竹筒, 有错就削去</p>
<p>不足之训: 不值得作为效法的准则或榜样</p>
<hr>
<p>也许马年春节是鲨鱼过得最开心的春节了, 因为新的一年以节约开启, 而非杀戮. —英国卫报报道中国假日反腐如是说</p>
<p>节俭是你一生中食之不完的美筵. —爱默生</p>
]]></content>
      <categories>
        <category>record</category>
      </categories>
  </entry>
  <entry>
    <title>中华茶楼</title>
    <url>/2021/09/15/zhonghuachalou/</url>
    <content><![CDATA[<p>2021.9.15</p>
<h4 id="菜品"><a href="#菜品" class="headerlink" title="菜品"></a>菜品</h4><p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21091502.jpg" style="zoom: 10%;" /></p>
<center>凤爪 23元</center>

<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21091503.jpg" style="zoom: 10%;" /></p>
<center>牛仔骨 28元</center>

<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21091504.jpg" style="zoom: 10%;" /></p>
<center>虾饺 28元</center>

<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21091505.jpg" style="zoom: 10%;" /></p>
<center>葡挞 20元</center>

<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21091506.jpg" style="zoom: 10%;" /></p>
<center>榴莲酥 20元</center>

<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21091507.jpg" style="zoom: 10%;" /></p>
<center>乳鸽 72元 2只</center>

<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21091508.jpg" style="zoom: 10%;" /></p>
<center>马拉糕 15元</center>

<center>外加5*3茶味费和未知费用, 每月第三个星期四五九折, 总价 255 * 0.59 = 150 元, 人均 50 元.</center>

<h4 id="餐厅环境"><a href="#餐厅环境" class="headerlink" title="餐厅环境"></a>餐厅环境</h4><p>客人较多时比较拥挤, 送餐车会占住整条走廊, 而且比较嘈杂, 和旁边人交流也要提起嗓门, 如果是多人大圆桌, 几乎听不到桌子对面的人说话.</p>
<h4 id="用餐时间"><a href="#用餐时间" class="headerlink" title="用餐时间"></a>用餐时间</h4><p>今天比较幸运, 1730来到不用排队, 上一次中午排了一个多小时. 大部分点心可凭每桌的点餐卡直接自取, 但其他菜品也需凭点餐卡下单, 下单到菜上桌期间没有点餐卡, 无法自取点心.</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21091509.jpg" style="zoom: 10%;" /></p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21091510.jpg" style="zoom: 10%;" /></p>
<center>自取点心</center>

<h4 id="餐厅位置"><a href="#餐厅位置" class="headerlink" title="餐厅位置"></a>餐厅位置</h4><p>肇庆市端州区棠岗路星湖尚景苑二期东城汇二楼(星湖东门牌坊直行800米)</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/21091501.jpg" style="zoom: 15%;" /></p>
<center> 蓝色楼顶那里 </center>

]]></content>
      <categories>
        <category>Restaurants</category>
      </categories>
  </entry>
  <entry>
    <title>DRL note</title>
    <url>/2021/09/13/DRL_note/</url>
    <content><![CDATA[<h2 id="3-4-价值函数"><a href="#3-4-价值函数" class="headerlink" title="3.4 价值函数"></a>3.4 价值函数</h2><p>状态价值函数 $V_{pi} ( s_t )$, 仅依赖于 $s_t$, 而 $a_t, s_{t+1}, a_{t+1},$…都被期望消掉了</p>
<p>动作价值函数 $Q(s_t, a_t)$, 仅依赖于 $s_t, a_t,$ 而 $s_{t+1}, a_{t+1}$,…都被期望消掉了</p>
<p>最优动作价值函数 $Q_\star (s,a) = \max_\pi Q (s,a)$, 若 $Q_\star$ 已知, 给定当前状态 $s$, 策略为选择使 $Q_\star$ 最大的 $a$</p>
<p>eg. $Q_\star(s, up) = 370, Q_\star(s, left) = -120, Q_\star(s, right) = 30$, 选 up.</p>
<p>已知 $s_t, a_t$, 无论未来采取什么策略, 回报 $U_t = R_t + \gamma R_{t+1} + \gamma^2 R_{t+2} + …$ 的期望不可能超过 $Q_\star$</p>
<p>DQN 学习出 $Q_\star$</p>
<h1 id="4-DQN-与-Q学习"><a href="#4-DQN-与-Q学习" class="headerlink" title="4 DQN 与 Q学习"></a>4 DQN 与 Q学习</h1><p>$Q_\star(s_t, a_t) = \mathbb{E}_{s_{t+1} \sim p(\cdot | s_t, a_t)}\left[R_t + \gamma\max\limits_{a\in \mathcal{A}}Q_\star(s_{t+1}, a) \mid s_t, a_t\right]$</p>
<p>DQN 本质为对 $Q_\star$ 的函数近似</p>
<p>状态空间可以无限, 动作空间需要有限.</p>
<p>网络输入为状态 $s$, 输出每个动作的 $Q$ 值</p>
<p>收集样本 $(s_t, a_t, r_t, s_{t+1})$ 反向更新网络参数 $w$</p>
<p>DQN 属于异策略 (off-policy): 用于收集经验的<strong>行为策略</strong>($\epsilon$ greedy)与控制 Agent 的<strong>目标策略</strong>不同</p>
<p>SARSA 属于同策略 (on-policy)</p>
<h1 id="5-Sarsa"><a href="#5-Sarsa" class="headerlink" title="5 Sarsa"></a>5 Sarsa</h1><p>用于训练评价策略 $Q_\pi$</p>
<p>$Q_\pi(s_t, a_t) = \mathbb{E}_{s_{t+1},a_{t+1}}\left[R_t + \gamma Q_\pi(s_{t+1}, a_{t+1}) \mid s_t, a_t\right]$</p>
<h1 id="6-价值学习高级技巧"><a href="#6-价值学习高级技巧" class="headerlink" title="6 价值学习高级技巧"></a>6 价值学习高级技巧</h1><h3 id="经验回放"><a href="#经验回放" class="headerlink" title="经验回放"></a>经验回放</h3><p>存储多个四元组反复训练网络, 只适用于异策略, 否则对于同策略, 存储的都是过时策略的四元组</p>
<ul>
<li>优先经验回放: 数组样本的TD误差越大, 抽取到该样本用于训练网络的概率越大 (少见 危险情况)</li>
</ul>
<p>然而 DQN 的训练方法是自举的 (用一个估算去更新同类的估算), 这会导致偏差传播, 即高估会导致更高估</p>
<ul>
<li>见第4部分的第一条式子, 右边的max为现有估计, 若它被高估了, 则需要更新的等式左边也会被高估<ul>
<li>目标网络: 相当于新建一个 DQN, 用来算 TD 目标, 更新原 DQN, 再一定程度更新目标网络. 参数仍然与原 DQN 相关, 只能缓解自举, 不能根治.</li>
</ul>
</li>
<li>max本身就会使有噪声的无偏随机变量被高估<ul>
<li>双Q: 用 DQN 算 $a_\star$ , 用目标网络算 TD 目标.</li>
</ul>
</li>
</ul>
<p>对决网络: $Q(s,a;w) = V(s;w^V) + D(s,a;w^D) - \max\limits_{a \in \mathcal{A}}D(s,a;w^D)$. 训练最优优势 $D_\star$ 与最优状态价值 $V_\star$ 两个网络从而近似 $Q_\star$</p>
<p>噪声网络: 参数 $w$ 的每个参数 $w_i = \mu_i + \sigma_i \cdot \xi_i$, 即 均值+标准差x噪声. 每做一次决策, 噪声需重新随机生成. 参数数量多一倍. 可以不用 $\epsilon-$greedy</p>
<h1 id="7-策略梯度"><a href="#7-策略梯度" class="headerlink" title="7 策略梯度"></a>7 策略梯度</h1><p>$\max\limits_{\theta} J(\theta) = \mathbb{E}_s[V_\pi(s)]$</p>
<p>梯度上升</p>
<p>$\nabla_\theta J(\theta)$ 的一个无偏估计为 $g(s,a;\theta) = Q_\pi(s,a) \cdot \nabla_\theta \ln \pi(a\mid s;\theta)$</p>
<p>$\theta \leftarrow \theta + \beta\cdot g(s,a;\theta)$​</p>
<p>策略网络: 针对有限的动作空间, 输入状态 $s$, 输出各动作概率 $\pi(\cdot \mid s_t; \theta)$​</p>
<h3 id="Reinforce"><a href="#Reinforce" class="headerlink" title="Reinforce"></a>Reinforce</h3><p>玩一盘游戏得到 $u_t = r_t + \gamma r_{t+1} + …$ 用其近似 $Q_\pi(s,a)$</p>
<p>同策略 (策略网络)</p>
<h3 id="Actor-Critic"><a href="#Actor-Critic" class="headerlink" title="Actor-Critic"></a>Actor-Critic</h3><p>策略网络(Actor) + 价值网络(Critic)</p>
<p>训练价值网络近似 $Q_\pi(s,a)$</p>
<p>训练算法为 SARSA, 同策略</p>
<p>也可以用目标网络 (价值网络) 缓解自举</p>
<h1 id="8-带基线的策略梯度"><a href="#8-带基线的策略梯度" class="headerlink" title="8 带基线的策略梯度"></a>8 带基线的策略梯度</h1><h3 id="Reinforce-1"><a href="#Reinforce-1" class="headerlink" title="Reinforce"></a>Reinforce</h3><p>$g_b(s,a;\theta) = [ Q_\pi(s,a) - b ] \cdot \nabla_\theta \ln \pi(a\mid s;\theta)$ </p>
<p>只要 $b$ 不依赖与动作 $A$, $g_b(s,a;\theta)$ 依然是 $\nabla_\theta J(\theta)$ 的一个无偏估计</p>
<p>可令 $b = V_\pi(s)$, 新建价值网络近似 $V_\pi(s)$</p>
<p>Reinforce $u_t$​ 近似 $Q_\pi(s,a)$​, 同时基于 $u_t$​​ 更新价值网络的参数</p>
<hr>
<h3 id="Advantage-Actor-Critic-A2C"><a href="#Advantage-Actor-Critic-A2C" class="headerlink" title="Advantage Actor-Critic (A2C)"></a>Advantage Actor-Critic (A2C)</h3><p>恰好 $Q_\pi(s,a) - V_\pi(s)$​ 为优势函数​ Advantage Function</p>
<p>策略网络与价值网络的结构与带基线的 Reinforce 相同, 训练方法不同.</p>
<p>训练价值网络:</p>
<ul>
<li><p>基于 Bellman 方程 $V_\pi(s_t) = \mathbb{E}_{A_t,S_t} [R_t + \gamma \cdot V_\pi(S_{t+1})]$</p>
</li>
<li><p>TD 目标为 $r_t + \gamma \cdot V(s_{t+1};w)$​</p>
</li>
</ul>
<p>训练策略网络:</p>
<ul>
<li>$g(s_t,a_t;\theta) = [ r_t + \gamma \cdot V(s_{t+1};w) - V(s_{t};w) ] \cdot \nabla_\theta \ln \pi(a\mid s;\theta)$​</li>
</ul>
<p>同策略 (策略网络)</p>
<h1 id="9-策略学习高级技巧"><a href="#9-策略学习高级技巧" class="headerlink" title="9 策略学习高级技巧"></a>9 策略学习高级技巧</h1><h3 id="TRPO"><a href="#TRPO" class="headerlink" title="TRPO"></a>TRPO</h3><p>Trust Region Policy Optimization 置信域策略优化</p>
<p>置信域 $\mathcal{N}(\theta_{now})$: $\theta_{now}$​ 的一个邻域, 在这个邻域内的 $\theta$​, 函数 $L(\theta \mid \theta_{now})$ 很接近 $J(\theta)$​.<br>$J(\theta) = \mathbb{E}_S [V_\pi(S)]$</p>
<p>$ = \mathbb{E}_S [\sum\limits_{a\in \mathcal{A}} \pi(a\mid S;\theta)Q_\pi(S,a)]$​</p>
<p>$= \mathbb{E}_S [\sum\limits_{a\in \mathcal{A}} \pi(a\mid S;\theta_{now})\frac{\pi(a\mid s;\theta)}{\pi(a\mid S;\theta_{now})}Q_\pi(S,a)]$​​</p>
<p>$= \mathbb{E}_S [\mathbb{E}_{A \sim \pi(\cdot \mid S; \theta_{now})} [\frac{\pi(A\mid S;\theta)}{\pi(A\mid s;\theta_{now})}Q_\pi(S,A)]]$​</p>
<ol>
<li><p>做近似<br> 由轨迹蒙特卡洛<br> $L(\theta \mid \theta_{now}) = \frac{1}{n} \sum\limits_{t=1}^n \frac{\pi(a_t\mid s_t;\theta)}{\pi(a_t\mid s_t;\theta_{now})} \cdot u_t$</p>
</li>
<li><p>最大化</p>
<p>$\max_\theta L(\theta \mid \theta_{now}); \textsf{st} ~\theta \in \mathcal{N}(\theta_{now})$</p>
<p>用球或 KL 散度($\pi$​ 的接近程度) 决定邻域</p>
</li>
</ol>
<h3 id="熵正则-Entropy-Regularization"><a href="#熵正则-Entropy-Regularization" class="headerlink" title="熵正则 Entropy Regularization"></a>熵正则 Entropy Regularization</h3><p>对概率分布 $p = [p_1,…,p_n]$, Entropy$(p) = -\sum\limits_{i=1}^n p_i\ln p_i$</p>
<p>增大熵以增强策略的随机性(探索能力), 作为正则项加入目标函数</p>
<p>定义 $H(s;\theta) = \textsf{Entropy}(\pi(\cdot\mid s;\theta)) = -\sum\limits_{a \in \mathcal{A}} \pi(a \mid s;\theta)\ln \pi(a\mid s;\theta)$</p>
<p>$\max_{\theta} ~j(\theta) + \lambda\mathbb{E}_S[H(S;\theta)]$</p>
<p>策略梯度 (Reinforce, AC), TRPO等求解</p>
<h1 id="10-连续控制"><a href="#10-连续控制" class="headerlink" title="10 连续控制"></a>10 连续控制</h1><p>动作空间为连续集合 [0,1] vs {0,1}</p>
<h3 id="转化为离散-网格化"><a href="#转化为离散-网格化" class="headerlink" title="转化为离散 (网格化)"></a>转化为离散 (网格化)</h3><p>会维度灾难</p>
<h3 id="确定策略梯度-DPG"><a href="#确定策略梯度-DPG" class="headerlink" title="确定策略梯度 DPG"></a>确定策略梯度 DPG</h3><p>Deterministic Policy Gradient</p>
<p>Actor-Critic 其中策略网络的输出由各动作的概率向量变为一个确定的动作 $a = \mu(s;\theta)$</p>
<p>异策略 行为策略为旧策略网络+噪声</p>
<p>价值网络打分 $q(s, \mu(s;\theta); w)$</p>
<p>$\max_{\theta} J(\theta) = \mathbb{E}[q(s, \mu(s;\theta); w)]$</p>
<p>$g_j = \nabla_{\theta} q(s, \mu(s;\theta);w) = \nabla_{\theta} \mu(s;\theta)\cdot\nabla_{\mu(s;\theta)}(q(s, \mu(s;\theta);w))$</p>
<p>梯度上升训练策略网络</p>
<p>TD 算法训练价值网络</p>
<h5 id="双延时确定策略梯度-TD3"><a href="#双延时确定策略梯度-TD3" class="headerlink" title="双延时确定策略梯度 TD3"></a>双延时确定策略梯度 TD3</h5><p>缓解最大化与自举问题                                                                                                                                                                                                                                                                                                                                                                                                                                             </p>
<p>Twin Delayed Deep Deterministic Policy Gradient</p>
<ul>
<li>1 策略网络</li>
<li>1 目标策略网络</li>
<li>2 价值网络</li>
<li>2 目标价值网络</li>
</ul>
<p>取两个目标价值网络的较低分数作为 TD 目标 (截断双 Q 学习)</p>
<p>还可往动作中加噪声, 减小除价值网络外的网络更新频率 (先让价值网络慢慢学好一点)</p>
<h3 id="随机高斯策略"><a href="#随机高斯策略" class="headerlink" title="随机高斯策略"></a>随机高斯策略</h3><p>从高斯分布获得动作, 均值 $\mu(s)$​, 标准差 $\sigma(s)$, 即每个状态对应一个高斯分布.</p>
<p>$\pi(a \mid s ) = \frac{1}{\sqrt{2\pi}\sigma(s)} \cdot \exp(-\frac{[a - \mu(s)]^2}{2\sigma^2(s)})$​​​ (动作为一维)</p>
<p>构造均值网络 $\mu(s;\theta)$​ 与方差对数 ($\ln \sigma^2$​) 网络 $\rho (s;\theta)$$\pi(a \mid s ; \theta) = \Pi_{i=1}^d \frac{1}{\sqrt{2\pi} \exp[\rho_i(s;\theta)]} \cdot \exp(-\frac{[a_i - \mu_i(s;\theta)]^2}{2\exp[\rho_i(s;\theta)]})$​</p>
<p>实际中定义辅助网络 $f(s,a;\theta) = -\frac{1}{2}\sum\limits_{i=1}^d(\rho_i(s;\theta) + \frac{[a_i - \mu_i(s;\theta)]^2}{\exp[\rho_i(s;\theta)]})$</p>
<p>$f(s,a;\theta) = \ln\pi(a\mid s; \theta) + \textsf{constant}$</p>
<p>策略梯度 $g = Q_\pi(s,a) \nabla_{\theta} \ln\pi(a \mid s;\theta) = Q_\pi(s,a) \nabla_{\theta} f(s,a;\theta)$</p>
<p>用 Reinforce with baseline, A2C 近似 $Q_\pi(s,a)$</p>
<h1 id="十一-对状态的不完全观测"><a href="#十一-对状态的不完全观测" class="headerlink" title="十一 对状态的不完全观测"></a>十一 对状态的不完全观测</h1><p>$\pi(a \mid s ; \theta) \rightarrow \pi(a \mid o_{1:t} ; \theta)$</p>
<p>t 可变, 即网络的输入形状可变, 不能直接使用卷积层/全连接层.</p>
<p>循环神经网络 RNN Recurrent NN, 把一个序列映射到一个特征向量</p>
<p>$(x_1,…,x_i) \rightarrow h_i, h_i(i=1,…,n)$ 的维度都相同, 且 $h_i$ 包含 $x_1,…,x_i$ 的所有信息, 也即最后只需保留 $h_n$​, 作为传统输入送给神经网络.​</p>
<p>$h_t = \tanh (W[h_{t-1};x_t]+b)$, 矩阵 $W$, 向量 $b$​ 为 RNN 的参数.​</p>
<p>当 RNN 作为策略网络, 只需将 $h_t$ 作为全连接网络的输入, 输出 $|\mathcal{A}|$ 维的动作概率向量.</p>
<p>类似搭建 DQN $Q(o_{1:t}, a_t; w)$ 与价值网络 $q(o_{1:t}, a_t; w)$</p>
<h1 id="十二-并行计算"><a href="#十二-并行计算" class="headerlink" title="十二 并行计算"></a>十二 并行计算</h1><p>重复以下步骤直到收敛</p>
<ol>
<li>广播 (Broadcast): 服务器广播模型参数到所有节点 (老板给打工仔发任务)</li>
<li>映射 (Map): 节点用本地数据计算 (打工仔干活)</li>
<li>规约 (Reduce): 节点将信息发送回服务器 (打工仔交活儿)</li>
<li>更新参数: 老板准备明天干什么活儿?</li>
</ol>
<ul>
<li>同步算法: 所有节点都完成映射计算后, 系统才能执行规约通信 (短板效应)</li>
<li>异步算法: 节点之间不等待, 需要服务器能够与每个节点单独通信, 接收到任一节点的结果后就更新参数, 即不同节点的参数通常是不同的.</li>
</ul>
<p>异步算法可用于 DQN, Asynchronous A2C (A3C), 服务器处理网络参数.</p>
<h1 id="十三-多智能体系统"><a href="#十三-多智能体系统" class="headerlink" title="十三 多智能体系统"></a>十三 多智能体系统</h1><ul>
<li><p>合作关系 Fully Cooperative</p>
<p>$R_t^1 = R_t^2 = … = R_t^m, m\textsf{个Agent},~\forall t$​​</p>
</li>
<li><p>竞争关系 Fully Competitive</p>
<p>双方奖励负相关, 例如零和博弈, 奖励之和为 0</p>
</li>
<li><p>合作竞争混合 Mixed Cooperative &amp; Competitive</p>
<p>分为多个群组, 组内合作, 组件竞争, 例如踢足球</p>
</li>
<li><p>利己主义 Self-Interested</p>
<p>只想最大化自身累计奖励</p>
</li>
</ul>
<p>策略网络为 $\pi(\cdot \mid s; \theta^i)$​ or $\mu(s;\theta^i)$</p>
<p>动作价值函数 $Q_\pi^i(s_t,a_t) = \mathbb{E}_{S_{t+1},…,S_n,A_{t+1},…,A_n}[U_t^i \mid S_t=s_t, A_t = a_t]$</p>
<p>整体动作 $A$ 的概率密度函数 $\pi(A\mid S;\theta^1,…,\theta^m) = \Pi_{i=1}^m \pi(A^i \mid S;\theta^i)$</p>
<p>状态价值函数 $V_\pi^i(s) = \mathbb{E}_A[Q_\pi^i(s,A)] = \sum\limits_{a^1 \in \mathcal{A}^1}\sum\limits_{a^2 \in \mathcal{A}^2}…\sum\limits_{a^m \in \mathcal{A}^m} \pi(A\mid S;\theta^1,…,\theta^m)Q_\pi^i(s,a)$</p>
<h1 id="十四-合作关系-MARL"><a href="#十四-合作关系-MARL" class="headerlink" title="十四 合作关系 MARL"></a>十四 合作关系 MARL</h1><p>$S = [O^1,O^2,…,O^m]$</p>
<p>$R,U,Q,V,J$ 均相同</p>
<h3 id="MAC-A2C"><a href="#MAC-A2C" class="headerlink" title="MAC-A2C"></a>MAC-A2C</h3><p>Multi-Agent Cooperative Advantage Actor-Critic</p>
<ul>
<li><p>价值网络: $v(s;w)$​​. 所有 Agent 共用, 输入为上方定义的 s, 输出为对 s 的评分 .TD 算法训练.</p>
</li>
<li><p>策略网络: $\pi(\cdot \mid s;\theta^i)$​. 每个 Agent 独有, 输入为 s, 输出为 $\mathcal{A}^i$ 的概率分布</p>
<p>$\nabla_{\theta^i} J(\theta^1,…,\theta^m) = \mathbb{E}_{S,A}[(Q_\pi(S,A) - V_\pi(S))\cdot\nabla_{\theta^i} \ln\pi(A^i\mid S;\theta^i)]$</p>
<p>$g^i(s,a;\theta^i) = (Q_\pi(s,a) - V_\pi(s))\cdot\nabla_{\theta^i} \ln\pi(a^i\mid s;\theta^i)$</p>
<p>$g^i(s_t,a_t;\theta^i) = (r_t+\gamma \cdot v(s_{t+1};w) - v_\pi(s_t;w))\cdot\nabla_{\theta^i} \ln\pi(a_t^i\mid s_t;\theta^i)$</p>
</li>
</ul>
<p>同策略 $\pi(\cdot\mid s_t;\theta^i)$</p>
<p>Agent 不能独立做决策, 需要知道所有 Agent 的观测, 即全局状态.</p>
<p><img src="https://raw.githubusercontent.com/LLLLLH76/blog-img/main/1.png" alt=""></p>
<p>trade-off: 通信慢, 但不近似网络, 效果好.</p>
<ul>
<li>中心化训练+中心化决策: 1 个价值网络 + m 个策略网络, 中央收集各 Agent 的观测, 分配决策, Agent 完全不用思考. 由于必须等待所有观测组成状态, 产生短板效应, 延迟高.</li>
<li>去中心化训练+去中心化决策: m 个价值网络(输入为 $o^i$ 而非 $s$) + m 个策略网络(输入为 $o^i$ 而非 $s$), Agent 之间不通信, 参数独立, 本质为 SARL.</li>
<li>中心化训练+去中心化决策: 1 个价值网络 + m 个策略网络(输入为 $o^i$ 而非 $s$), 中央收集各 Agent 的观测, 训练价值网络的同时将 TD 误差广播到所有 Agent ,每个 Agent 更新自己的策略网络.</li>
</ul>
<h1 id="十五-非合作关系-MARL"><a href="#十五-非合作关系-MARL" class="headerlink" title="十五 非合作关系 MARL"></a>十五 非合作关系 MARL</h1><p>$S = [O^1,O^2,…,O^m]$</p>
<p>$R,U,Q,V,J$​​ 不相同</p>
<p>$J^i(\theta^1,…,\theta^m) = \mathbb{E}[V_\pi^i(s)]$​</p>
<p>每个 Agent 求解 $\max_{\theta^i} J^i(\theta^1,…,\theta^m)$</p>
<p>收敛判别为纳什均衡: 当其余所有 Agent 都不改变策略的情况下, 一个 Agent $i$ 单独改变策略 $\theta^i$​ 无法令 $J^i$ 变大.</p>
<p>两次学习优劣评价: 交换对手.</p>
<h3 id="MAN-A2C"><a href="#MAN-A2C" class="headerlink" title="MAN-A2C"></a>MAN-A2C</h3><p>Multi-Agent Non-cooperative A2C</p>
<p>m 个策略网络 + m 个价值网络</p>
<p>$\nabla_{\theta^i} J(\theta^1,…,\theta^m) = \mathbb{E}_{S,A}[(Q_\pi^i(S,A) - V_\pi^i(S))\cdot\nabla_{\theta^i} \ln\pi(A^i\mid S;\theta^i)]$​</p>
<p>  $g^i(s_t,a_t^i;\theta^i) = (r_t^i+\gamma \cdot v(s_{t+1};w^i) - v_\pi(s_t;w^i))\cdot\nabla_{\theta^i} \ln\pi(a_t^i\mid s_t;\theta^i)$​</p>
<p>同策略 $\pi(\cdot\mid s_t;\theta^i)$​</p>
<ul>
<li>中心化训练+中心化决策: 中央收集各 Agent 的观测, m 个评委分别评价各个Agent, m 个策略网络产生动作.</li>
<li>去中心化训练+去中心化决策: 价值网络与策略网络输入为 $o^i$ 而非 $s$, Agent 之间不通信, 参数独立, 奖赏各不相同. 本质为 SARL.</li>
<li>中心化训练+去中心化决策: 策略网络输入为 $o^i$ 而非 $s$​​​​, 与 MAC-A2C 的中心化训练+去中心化决策基本相同, 区别在于有 m 个价值网络而非 1 个.</li>
</ul>
<hr>
<h3 id="MADDPG"><a href="#MADDPG" class="headerlink" title="MADDPG"></a>MADDPG</h3><p>Multi-Agent Deep Deterministic Policy Gradient 多智能体深度确定策略梯度</p>
<p>连续控制 异策略 中心化训练+去中心化决策</p>
<p>训练单个 Agent 的策略网络与价值网络需要一个经验回放与所有策略网络, 因此只能中心化训练.</p>
<h1 id="十六-注意力机制与-MARL"><a href="#十六-注意力机制与-MARL" class="headerlink" title="十六 注意力机制与 MARL"></a>十六 注意力机制与 MARL</h1><p>自注意力层 Self-Attention Layer: 输入为 $(x^1,…,x^m)$, 输出为 $(c^1,…,c^m)$, $m$ 可变, $c^i$ 与 $(x^1,…,x^m)$ 相关. 此前的 RNN 只与  $(x^1,…,x^i)$​ 相关.</p>
<p>$ q^i = W_q x^i ,  ~k^i = W_k x^i , ~v^i = W_v x^i$</p>
<p>$\alpha^i = softmax[(q^i)^\top k^1,…,(q^i)^\top k^m]$</p>
<p>$c^i = [v^1,…,v^m]\cdot \alpha^i = \alpha_1^i v^1 + … + \alpha_m^i v^m$</p>
<p>$c^i$ 主要取决于最密切相关的一个或几个 $x~\rightarrow~ $一个 Agent 学会判断哪些 Agent 最相关并重点关注. $c^i$ 作为全连接网络的输入. </p>
<p>多头(Multi-Head)自注意力层将单头(Single-Head)自注意力层的输出连接起来.</p>
<p>可用于策略网络与价值网络, 离散与连续.</p>
<p>可将中心化的 $m$ 个价值网络/策略网络用 1 个带自注意力层的网络实现. $m$​ 越大效果越好.</p>
<h1 id="十七-模仿学习"><a href="#十七-模仿学习" class="headerlink" title="十七 模仿学习"></a>十七 模仿学习</h1><p>Imitation Learning</p>
<p>不是强化学习. 通过向人类专家学习策略网络, 使其做出与专家相同决策, 而非强化学习使累计奖励最大化. 训练成本低 (无人驾驶不用撞车).</p>
<h3 id="行为克隆"><a href="#行为克隆" class="headerlink" title="行为克隆"></a>行为克隆</h3><p>本质为监督学习, 数据集为 \{(状态, 动作)\}, 不需要与环境交互.</p>
<ul>
<li>连续控制: 回归</li>
<li>离散控制: 多类别分类器, 输出各动作概率</li>
</ul>
<h3 id="逆向强化学习-Inverse-RL"><a href="#逆向强化学习-Inverse-RL" class="headerlink" title="逆向强化学习 Inverse RL"></a>逆向强化学习 Inverse RL</h3><p>根据人类专家的策略学习奖赏关于状态与动作的函数, 再用其训练策略.</p>
<h3 id="GAIL"><a href="#GAIL" class="headerlink" title="GAIL"></a>GAIL</h3><p>Generative Adversarial Imitation Learning</p>
<h4 id="生成判别网络-GAN"><a href="#生成判别网络-GAN" class="headerlink" title="生成判别网络 GAN"></a>生成判别网络 GAN</h4><p>Generative Adversarial Network</p>
<ul>
<li>生成器: $a = G(s;\theta)$, 由随机向量 $s$ 生成假样本</li>
<li>判别器: $\hat{p} = D(x;\Phi)$, 判断样本 $x$ 是真的概率</li>
</ul>
<p>同时训练两者, 增强生成器以假乱真与判别器判别的能力.</p>
<p>GAIL 的生成器是策略网络, 输入状态输出动作. 判别器输入状态, 输出 $|\mathcal{A}|$ 维向量 $\hat{p}$, 每个元素 $\hat{p}_a \in (0,1)$ 表示 $(s,a)$ 真假程度 ($a$ 是否为人类专家(真样本)所做)</p>
<h1 id="十八-AlphaGo-与-MCTS"><a href="#十八-AlphaGo-与-MCTS" class="headerlink" title="十八 AlphaGo 与 MCTS"></a>十八 AlphaGo 与 MCTS</h1>]]></content>
      <categories>
        <category>lecture notes</category>
      </categories>
  </entry>
</search>
